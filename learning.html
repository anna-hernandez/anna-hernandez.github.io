<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Professional Website</title>
        <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v6.3.0/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
            <a class="navbar-brand js-scroll-trigger" href="#page-top">
                <span class="d-block d-lg-none">Anna Hernandez, PhD.</span>
                <span class="d-none d-lg-block"><img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="" alt="..." /></span>
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav">
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="index.html">About</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="cv.html">Experience</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="learning.html">Learning</a></li>
                </ul>
            </div>
        </nav>
        <!-- Page Content-->
        <div class="container-fluid p-0">
            <!-- About-->
            <section class="resume-section" id="about">
                <div class="resume-section-content">
                    <h1 class="mb-0">
                        <span class="text-primary">Core Concepts in Machine Learning.</span>
                    </h1>
                    <div class="subheading mb-5">
                        Concepts
                    </div>
                    <ol>Concepts</ol>
                        <li>Fitting: the process of finding the best parameter values to build the model, using the training data</li>
                        <li>Optimisation: the way in which to find the best parameters (fitting) in the most efficient way. Usually, the parameter value space is vast, and exploring all possible values or ways to get to the optimal value is... tedious and lengthy to say the least. Optimisation techniques guide us to get there faster.</li>
                        <li>MLE, LL, NLL</li>
                    <ol>Types of ML</ol>
                        <li>Supervised Learning</li>
                        <li>Unsupervised Learning</li>
                        <li>Semi-Supervised Learning</li>
                        <li>Reinforcement Learning</li>
                    <ol>Model Evaluation</ol>
                        <li>Train/Test Split</li>
                        <li>Cross-Validation</li>
                        <li>Bias-Variance Tradeoff</li>
                    <ol>Performance Metrics</ol>
                        <li>Classification Metrics</li>
                            <ul>
                                <li>Accuracy</li>
                                <li>Precision</li>
                                <li>Recall</li>
                                <li>F1-Score</li>
                                <li>ROC-AUC</li>
                            </ul>
                        <li>Regression Metrics</li>
                            <ul>
                                <li>Mean Absolute Error (MAE)</li>
                                <li>Mean Squared Error (MSE)</li>
                                <li>Root Mean Squared Error (RMSE)</li>
                                <li>R-squared</li>
                            </ul>
                    </ol>
                    <span class="text-primary">Traditional Machine Learning Algorithms</span>
                    <p class="lead mb-5">A summary of core (if not <it>the</it> core) algorithms that compose traditional machine learning techniques: Logistic Regression, Decision Trees, Random Forests, Gradient Boosting Machines, Support Vector Machines, K-Nearest Neighbors, K-Means Clustering, Hierarchical Clustering, Principal Component Analysis, Natural Language Processing</p>
                    <span class="text-primary">Linear Classifiers</span>
                    <div class="subheading mb-5">
                        Logistic Regression
                    </div>
                    <p class="lead mb-5">Logistic Regression is a classification method that fits the data points in the training set to a line and puts that line through a sigmoid function that separates the points into one of two classes. When a new data point appears, and it's run through the model, this maps the input value to a value between 0 and 1, which can be interpreted as a probability.

                    The fitting of the line is done through Maximum Likelihood Estimation (MLE), which finds the parameters that maximize how likely it is to observe the data based on the model that we are buildling. The optimization is usually performed using algorithms like Gradient Descent or Newton-Raphson.
                    </p>
                    <div class="subheading mb-5">
                        Gradient Descent
                    </div>
                    <p class="lead mb-5">Gradient descent is an optimisation algorithm used in machine learning to adjust the value of the weights (parameters) of the model so that the model gets closer to its optimal (i.e. minimises the cost function). Gradient descent calculates the gradient of a function at a given point and substracts that value multiplied by a small factor (called the learning rate) to the current value of the weights. The gradient points to the direction of growth of the function, hence the negative of the gradient (gradient substraction) points to the direction of decrease of the function. This means that the new value of the weights should provide s a lower value of the cost function. This process is repeated iteratively until convergence is reached (i.e. the weights no longer change significantly between iterations) or a predefined number of iterations is completed.

                    There are different types of gradient descent. The classic one, takes each point of the training set one by one and updates the weights accordingly. In practice, this is the most accurate way to update the weights but not the most efficient. So other versions have been created which, although they are not as accurate at each iteration, they are much cheaper in memory and time, i.e. they are faster. And because they are faster, they also allow us to run more iterations than classic gradient descent, hence we pretty much get to the same point.
                    
                    This is called Batch Gradient Descent. Another version, Stochastic Gradient Descent, takes one random point from the training set at each iteration to update the weights. A third version, Mini-Batch Gradient Descent, takes a small random subset of points from the training set at each iteration to update the weights. Each version has its pros and cons in terms of convergence speed and stability.
                    <span>Check out mini-batch, stochastic deefinitions</span>
                    We also have adaptive gradient descent, which has a changing learning rate based on the steepness of the gradient. <span>Adam, AdaGrad, RMSProp are examples of adaptive gradient descent algorithms.</span>
                    <span>Momentum gradient descent</span>
                    
                    As an overall tip: normalise your data before applying gradient descent, as this will help the algorithm converge faster and more reliably.
                    </p>
                </div>
            </section>
            <hr class="m-0" />
        </div>
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
